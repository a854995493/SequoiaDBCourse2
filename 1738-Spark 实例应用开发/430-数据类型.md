---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍 Spark SQL 支持的一些常见数据类型，以及 Spark SQL 数据类型和 SequoiaDB 数据类型的映射关系。实验过程中将通过 JDBC 在 Spark SQL 中创建 SequoiaDB 集合的映射表，并插入不同类型的数据，观察不同数据类型在 Spark 和 SequoiaDB 中的兼容情况。

#### 请点击右侧选择使用的实验环境

#### 部署架构

本课程中 SequoiaDB 巨杉数据库的集群拓扑结构为三分区单副本，其中包括：

* 1 个 SequoiaSQL-MySQL 数据库实例节点
* 1 个引擎协调节点
* 1 个编目节点
* 3 个数据节点

![1738-410-06](https://doc.shiyanlou.com/courses/1738/1207281/ff2754d609aba12340efeb27ce0645bb-0)

在当前实验的部署架构中，Spark 通过 MySQL 实例间接访问 SequoiaDB 存储集群，也可以通过 SequoiaDB 的 Spark 连接驱动直接访问底层的 SequoiaDB 存储集群。

详细了解 SequoiaDB 巨杉数据库系统架构：

* [SequoiaDB 系统架构](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1519649201-edition_id-0)

#### 实验环境

课程使用的系统环境为 Ubuntu 16.04.6 LTS 版本。SequoiaDB 数据库引擎以及 SequoiaSQL-MySQL 实例均为 3.4 版本。Spark 计算引擎为 2.4.3 版本。

## 打开项目

#### 打开 IDEA

1）打开 IDEA 代码开发工具。

![1738-410-07](https://doc.shiyanlou.com/courses/1738/1207281/72397a857808ab74f01b042f07ea0a27-0)

#### 打开 SCDD-Spark 项目

2）打开 Spark 实验的项目，在该项目中完成所有实验步骤。

![1738-410-08](https://doc.shiyanlou.com/courses/1738/1207281/5497d93bf19ee0442b4ae79b4cd8d39a-0)

#### Maven 依赖

实验环境中已经在 Maven 本地仓库添加了实验所需的依赖。当前实验使用到的 jar 包依赖以及依赖说明如下：

* hive-jdbc-1.2.1.spark.jar

  用于在 Java 程序中通过 JDBC 访问 Spark SQL

* spark-sequoiadb_2.11-3.2.4.jar

  用于在 Spark SQL 中创建 SequoiaDB 集合的映射

* fastjson-1.2.58.jar

  用于程序中格式化打印 SequoiaDB 集合中的记录

pom.xml 文件位置：

![1738-410-pom文件位置](https://doc.shiyanlou.com/courses/1738/1207281/9792106157a176f82acdaebf04961568-0)

当前实验中使用到的 Maven 依赖如下：

![1738-410-maven1](https://doc.shiyanlou.com/courses/1738/1207281/b0f437f18a0a276bbf404da17fef9a2c-0)

![1738-410-maven2](https://doc.shiyanlou.com/courses/1738/1207281/3d62b4c63338baa02ce4337f029ff166-0)

![1738-430-maven3](https://doc.shiyanlou.com/courses/1738/1207281/b849db56b5651754fad5ff0e3115d1ac-0)

> **说明**
>
> spark-sequoiadb_2.11-3.2.4.jar 可以在 [SequoiaDB 巨杉数据库下载中心](http://download.sequoiadb.com/cn/driver) 获取。

#### 打开 Package

3）如图所示找到当前实验程序所在 Package，在该 Package 中完成后续实验步骤：

![1738-430-package](https://doc.shiyanlou.com/courses/1738/1207281/0877a201c31cebb45fb304414b3c3446-0)

## 创建映射表

#### 概述

在上一章中介绍了 Spark 在在映射有数据的 SequoiaDB 集合时会自动生成表结构，实际上在映射无数据的 SequoiaDB 集合时也可以手动指定映射表的表结构。

以本课程使用到的 typelist 表为例：

> CREATE TABLE typelist(                                               -- 定义各个字段数据类型
>
>  IntegerType int,
>
>  LongType bigint,
>
>  DoubleType double,
>
>  DecimalType decimal(10,1),
>
>  StringType string,
>
>  BooleanType boolean,
>
>  DateType date,
>
>  TimestampType timestamp,
>
>  BinaryType binary,
>
>  ArrayType array<int>,
>
>  StructType struct < key:int , val:array<int> >
>
> ) USING com.sequoiadb.spark                                 -- 使用 SequoiaDB 的 Spark 连接驱动
>
> OPTIONS(
>
>  host 'sdbserver1:11810',                           -- 指定访问 SequoiaDB 使用的主机名（也可以是ip）和协调节点
>
>  collectionspace 'sample',                          -- 映射集合所在的集合空间名
>
>  collection 'typelist'                                     -- 映射集合名
>
> );                                                  * 由于 SequoiaDB 的连接鉴权默认是无密码的，用户名和密码在此可以省略
>

SequoiaDB 和 Spark SQL 的数据类型映射关系如下：

| SequoiaDB 类型 | SparkSQL 类型 | SQL 实例类型            |
| -------------- | ------------- | ----------------------- |
| int32          | IntegerType   | int                     |
| int64          | LongType      | bigint                  |
| double         | DoubleType    | double                  |
| decimal        | DecimalType   | decimal                 |
| string         | StringType    | string                  |
| ObjectId       | StringType    | string                  |
| boolean        | BooleanType   | boolean                 |
| date           | DateType      | date                    |
| timestamp      | TimestampType | timestamp               |
| binary         | BinaryType    | binary                  |
| null           | NullType      | null                    |
| BSON(嵌套对象) | StructType    | struct < field:type,… > |
| array          | ArrayType     | array < type >          |

> **说明**
>
> * 数组类型
>
>   Spark 的 **ArrayType** 数据类型为由 elementType 类型元素组成的序列值。指定字段类型为 ArrayType 写法如下：
>
>   ```sql
>   字段名 array<数组元素类型>
>   ```
>
> * 结构化类型
>
>   Spark 的 **StructType** 数据类型为一个拥有 **StructFields** (fields) 序列结构的值，StructField(name, dataType, nullable) 代表 StructType 中的一个字段，字段的名字通过 name 指定，dataType 指定field的数据类型，nullable 表示字段的值是否有null值。指定字段类型为 StructType 写法如下：
>
>   ```sql
>   字段名 struct<key:key类型,val:value类型>
>   ```
>
>   StructType 类型中可以嵌套其他类型，例如：
>
>   ```sql
>StructType struct<key:int,val:array<int>>
>   ```
> 

程序中将通过 JDBC 在 Spark SQL中创建 SequoiaDB 集合的映射表。

#### 操作步骤

1）打开 DataType 类。

![1738-430-打开类](https://doc.shiyanlou.com/courses/1738/1207281/88b9e626adbca61a2f89f7ed3fddc448-0)

2）复制创建映射表代码。运行程序时会自动创建 SequoiaDB 中的 typelist 集合。程序中将调用封装好的类获取 JDBC 连接，使用 JDBC 连接创建 Statement 执行创建映射表 SQL 语句，建表完成后将查询映射表的表结构，并将查询结果集打印至控制台。所有数据操作执行完毕后将释放 JDBC 资源。

```java
// Get Hive JDBC connection
Connection connection = HiveUtil.getConnection();
// Initialize Statement
Statement statement = null;
// Initialize ResultSet
ResultSet resultSet = null;
try {
    // Create Statement
    statement = connection.createStatement();
    // Drop the existing typelist table
    String dropTable = "DROP TABLE IF EXISTS typelist";
    // Execute the SQL statement of drop table
    statement.executeUpdate(dropTable);
    // Create Spark Table and specify the data type of each field
    String mappingCollection =
            "CREATE TABLE typelist(" +
                    "IntegerType int," +
                    "LongType bigint," +
                    "DoubleType double," +
                    "DecimalType decimal(10,1)," +
                    "StringType string," +
                    "BooleanType boolean," +
                    "DateType date," +
                    "TimestampType timestamp," +
                    "BinaryType binary," +
                    "ArrayType array<int>," +
                    "StructType struct<key:int,val:array<int>>" +
                    ") USING com.sequoiadb.spark " +
                    "OPTIONS(" +
                    "host 'sdbserver1:11810'," +
                    "collectionspace 'sample'," +
                    "collection 'typelist'" +
                    ")";
    // Execute the SQL statement of create table
    System.out.println("Creating mapping table in Spark SQL...");
    statement.execute(mappingCollection);
    // Get the structure of mapping table
    String getDesc =
            "DESC typelist";
    // Execute the SQL statement of getting mapping table structure to get the result set
    resultSet = statement.executeQuery(getDesc);
    //  Call the predefined result set to beautify the utility class and print the result set
    System.out.println("Printing table structure...");
    ResultFormat.printResultSet(resultSet);
} catch (SQLException e) {
    e.printStackTrace();
} finally {
    // Release Hive JDBC source
    HiveUtil.releaseSource(resultSet, statement, connection);
}
```

> **说明**
>
> ResultFormat 工具类为已经封装好的查询结果集打印类，用于美化结果集的打印；HiveUtil 工具类为已经封装好的 Hive JDBC 工具类，用于获取 JDBC 连接以及释放 JDBC 资源。封装的工具类在此不做赘述。

3）将创建数据库代码粘贴至 DataType 类 createTable 方法的 TODO code 1 注释区间内。

![1738-430-TODO1](https://doc.shiyanlou.com/courses/1738/1207281/fe4ecfcb207bf73bc330d022496c6d33-0)

代码块粘贴后如图所示（为展示效果已将 try 代码块折叠）：

![1738-430-DONE1](https://doc.shiyanlou.com/courses/1738/1207281/e65f42749bc1b23282c5c21d2c9d3ce6-0)

4）右键点击 DataTypeMainTest 类，选择 Create/Edit DataTypeMainTest.main() 编辑主函数参数。

![1738-430-编辑1](https://doc.shiyanlou.com/courses/1738/1207281/b09b241b3846072c7c888a1ec4958983-0)

5）编辑主函数参数为 createtable。

![1738-430-createtable](https://doc.shiyanlou.com/courses/1738/1207281/2f89a571c71cf57543d9f71526687fdd-0)

6）右键点击 DataTypeMainTest 类，选择 Run DataTypeMainTest.main() 运行程序。

![1738-430-运行1](https://doc.shiyanlou.com/courses/1738/1207281/13a7f13b02ebc6da2e9abaff67f73ea9-0)

7）查看运行结果。

![1738-430-结果1](https://doc.shiyanlou.com/courses/1738/1207281/b3dfff3e1d46271173523b15948f5e97-0)

## 插入记录

#### 概述

当前步骤程序将通过 JDBC 向 Spark SQL 映射表中插入一条包含不同数据类型字段的记录，分别在 Spark SQL 和 SequoiaDB 中查询，比较不同数据类型在 Spark SQL 和 SequoiaDB 中的存储情况。

#### 操作步骤

1）打开 DataType 类。

![1738-430-打开类](https://doc.shiyanlou.com/courses/1738/1207281/88b9e626adbca61a2f89f7ed3fddc448-0)

2）复制插入记录程序代码。程序中将调用封装好的类获取 JDBC 连接，使用 JDBC 连接创建 Statement 执行插入记录 SQL 语句，插入数据完成后将分别查询 typelist 映射表和 typelist 集合中的数据内容，并将查询结果集打印至控制台。所有数据操作执行完毕后将释放 JDBC 资源。

```java
// Get Hive JDBC connection
Connection connection = HiveUtil.getConnection();
// Initialize Statement
Statement statement = null;
// Initialize ResultSet
ResultSet resultSet = null;
try {
    // Create Statement
    statement = connection.createStatement();
    // SQL of insert record
    String insertRecord =
            "INSERT INTO typelist " +
                    "VALUES(" +
                    "1," +
                    "9223372036854775807," +
                    "3.1415," +
                    "3.14," +
                    "'abc'," +
                    "true," +
                    "current_date()," +
                    "current_timestamp()," +
                    "encode('qazwsxedc','UTF-8')," +
                    "array(1,2,3)," +
                    "struct(123,array(1,2,3))" +
                    ")";
    // Execute the SQL statement of insert record
    statement.executeUpdate(insertRecord);
    // SQL of query the mapping table result set 
    String getRecord = "SELECT * FROM typelist";
    // Execute the SQL of query result set
    resultSet = statement.executeQuery(getRecord);
    // Call the predefined result set to beautify the utility class and print the result set
    System.out.println("Printing record in Spark table...");
    ResultFormat.printResultSet(resultSet);
    // Call the predefined utility class to print SequoiaDB collection
    System.out.println("Printing record in SequoiaDB collection...");
    SdbUtil.printCollection("sample", "typelist");
} catch (SQLException e) {
    e.printStackTrace();
} finally {
    // Release Hive JDBC source
    HiveUtil.releaseSource(resultSet, statement, connection);
}
```

> **说明**
>
> ResultFormat 工具类为已经封装好的查询结果集打印类，用于美化结果集的打印；HiveUtil 工具类为已经封装好的 Hive JDBC 工具类，用于获取 JDBC 连接以及释放 JDBC 资源；SdbUtil 类为 SequoiaDB 操作工具类，此处调用该类的 printCollection 方法格式化打印 SequoiaDB 结果集。封装的工具类在此不做赘述。

3）将创建数据库代码粘贴至 DataType 类 insertRecord 方法的 TODO code 2 注释区间内。

![1738-430-TODO2](https://doc.shiyanlou.com/courses/1738/1207281/66f9ce444ddcc2ab865f5e5a9801dd25-0)

代码块粘贴后如图所示（为展示效果已将 try 代码块折叠）：

![1738-430-DONE2](https://doc.shiyanlou.com/courses/1738/1207281/32f06cb41f9ea9d5fda06bb4a14aee22-0)

4）右键点击 DataTypeMainTest类，选择 Create/Edit DataTypeMainTest.main() 编辑主函数参数。

![1738-430-编辑1](https://doc.shiyanlou.com/courses/1738/1207281/b09b241b3846072c7c888a1ec4958983-0)

5）编辑主函数参数为 insertrecord。

![1738-430-编辑2](https://doc.shiyanlou.com/courses/1738/1207281/765e84b082a8c53112165252d93e8a15-0)

6）右键点击 DataTypeMainTest 类，选择 Run DataTypeMainTest.main() 运行程序。

![1738-430-运行1](https://doc.shiyanlou.com/courses/1738/1207281/13a7f13b02ebc6da2e9abaff67f73ea9-0)

7）查看运行结果。

![1738-430-结果2](https://doc.shiyanlou.com/courses/1738/1207281/08cd1f9d80ce7639acb02bcffb483f28-0)

## 总结

本课程介绍了 Spark SQL 常见的数据类型以及它们和 SequoiaDB 支持的数据类型的映射关系，并通过实验在 Spark 中创建外部映射表的方式访问无记录的 SequoiaDB 集合并插入包含不同数据类型的记录，验证不同的数据类型在 Spark 和 SequoiaDB 的兼容能力。
